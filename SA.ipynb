{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_csv.reader object at 0x00000000092C7348>\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import numpy as np\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "'''\n",
    "import twitter\n",
    "api = twitter.Api(consumer_key='1JyxFD77cbNWFtuHPg9Qcw8I9',\n",
    "                 consumer_secret='8DUwmZXezxS7FYGy6S7bfKN1HsxksmxJ4A4qVw4Wy1MAXYMfJE',\n",
    "                 access_token_key='913162907629780992-k7BVVkhLCPX3xX0KNiKob3UfQjr09od',\n",
    "                 access_token_secret='ELXVySL3kyxkkdEXsjXdhW7roDtNuWGaiENveCt3qVMTD')\n",
    "print api.VerifyCredentials()\n",
    "\n",
    "def createTestData(search_string):\n",
    "    try:\n",
    "        tweets_fetched = api.GetSearch(search_string,count=100)\n",
    "        print \"Great! we fetched \"+str(len(tweets_fetched))+\" tweets \"+\"on \"+search_string\n",
    "        return [{\"text\":status.text,\"label\":None} for status in tweets_fetched]\n",
    "    except:\n",
    "        print \"Sorry!! no match\"\n",
    "        return None\n",
    "#search_string = raw_input(\"Enter your search pattern\")\n",
    "#testData = createTestData(search_string)'''\n",
    "\n",
    "#Function to create Training Data\n",
    "def createTrainingData(corpusFile):\n",
    "    trainingData=[]\n",
    "    with open(corpusFile,'rb') as tsvFile:\n",
    "        lineReader = csv.reader(tsvFile,dialect='excel-tab')\n",
    "        print lineReader\n",
    "        for row in lineReader:\n",
    "            if len(row) == 2:\n",
    "                sub_row = row[0].split(\"  \")\n",
    "                trainingData.append({\"tweet-id\":sub_row[0],\"label\":sub_row[1],\"tweet_text\":row[1]})\n",
    "            else:\n",
    "                trainingData.append({\"tweet-id\":row[0],\"label\":row[1],\"tweet_text\":row[2]})\n",
    "    return trainingData\n",
    "trainingData = createTrainingData(\"G:\\\\Doit\\\\UC_ACAD\\\\CS Courses\\\\NLP\\\\semEvalProject\\\\semval-task4-training data\\\\semval-task4-training data\\\\2016downloaded4-subtask A.tsv\")\n",
    "\n",
    "#PreProcessing of tweets using regular expression and nltk modules\n",
    "class PreProcessTweets:\n",
    "    def __init__(self):\n",
    "        #taking stopwords like a,an,the,by,punctuations,url,@symbols..\n",
    "        self._stopwords = set(stopwords.words('english')+list(punctuation)+['AT_USER','URL'])\n",
    "    def processTweets(self,list_of_tweets):\n",
    "        processedTweets=[]\n",
    "        #print list_of_tweets\n",
    "        for tweet in list_of_tweets:\n",
    "            processedTweets.append((self._processTweet(tweet['tweet_text']),tweet['label']))\n",
    "        return processedTweets\n",
    "    def _processTweet(self,tweet):\n",
    "        #processing tweets as below\n",
    "        # 1. convert all to lower cases\n",
    "        tweet = tweet.lower()\n",
    "        #2. Replace links with the word with \"URL\" so as to avoid stopwords\n",
    "        tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',tweet)\n",
    "        #3. Replace @username with \"AT_USER\" so as to avoid as stopwords\n",
    "        tweet = re.sub('@[^\\s]+','AT_USER',tweet)\n",
    "        #4. Remove # tags from words , eg: #love --> love\n",
    "        tweet = re.sub(r'#([^\\s])+',r'\\1',tweet)\n",
    "        #5.convert long words to short format\n",
    "        tweet=re.sub(r'(.?)\\1+', r'\\1\\1', tweet) \n",
    "        #6. Do Word tokenize\n",
    "        tweet = word_tokenize(tweet)\n",
    "        return [word for word in tweet if word not in self._stopwords]\n",
    "tweetProcessor = PreProcessTweets()\n",
    "PreProcessedTrainingData = tweetProcessor.processTweets(trainingData)\n",
    "\n",
    "#SVM Classifier Training\n",
    "svmTrainingData = [' '.join(tweet[0]) for tweet in PreProcessedTrainingData]\n",
    "vectorizer = CountVectorizer(min_df=1)\n",
    "X = vectorizer.fit_transform(svmTrainingData)\n",
    "vocabulary = vectorizer.get_feature_names()\n",
    "swn_weights = []\n",
    "for word in vocabulary:\n",
    "    #adding weights to the features by taking pos_score and neg_scores of word\n",
    "    try:\n",
    "        synset = list(swn.senti_synsets(word)) #taking synonyms of word\n",
    "        common_meaning = synset[0]\n",
    "        if common_meaning.pos_score() > common_meaning.neg_score():\n",
    "            weight = pos_score\n",
    "        elif common_meaning.pos_score() < common_meaning.neg_score():\n",
    "            weight = neg_score\n",
    "        else:\n",
    "            weight = 0\n",
    "    except:\n",
    "        weight =0\n",
    "    swn_weights.append(weight)\n",
    "swn_X = []\n",
    "for row in X:\n",
    "    swn_X.append(np.multiply(row,np.array(swn_weights)))\n",
    "swn_X = np.vstack(swn_X)\n",
    "\n",
    "#Lets map positive to 1,negative to 2\n",
    "labels_array={'positive':1,'negative':2}\n",
    "labels=[labels_array[tweet[1]] for tweet in PreProcessedTrainingData]\n",
    "y = np.array(labels)\n",
    "\n",
    "#build SVM classifier\n",
    "SVMClassifier = SVC()\n",
    "SVMClassifier.fit(swn_X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "swn_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
